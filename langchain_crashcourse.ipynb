{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "858e18c0-b2c2-4b8e-984d-244ab915337e",
   "metadata": {},
   "source": [
    "# Langchain Crash Course"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f971c0dd-2ff4-4aed-bc9a-c07b1c7c7552",
   "metadata": {},
   "outputs": [],
   "source": [
    "from secret_key import openapi_key\n",
    "# import os\n",
    "# os.environ['OPENAI_API_KEY'] = openapi_key\n",
    "\n",
    "import os\n",
    "os.environ['OPENAI_API_KEY'] = openapi_key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d290b0-4132-491b-914a-e729b150df2b",
   "metadata": {},
   "source": [
    "# LLMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c583178d-e8c2-4b95-9143-4b339720e686",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Saffron Spice Palace\"\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Create an instance of the ChatOpenAI model\n",
    "llm = ChatOpenAI(temperature=0.9)\n",
    "\n",
    "# Use .invoke() instead of .predict()\n",
    "name = llm.invoke(\"I want to open a restaurant for Indian food. Suggest a fancy name for this.\")\n",
    "print(name.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "27b74b14-840d-443a-ac04-fd4f9690e8b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"Spice Palace\"'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"I want to open a restaurant for Indian food. Suggest a fancy name for this.\").content\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a6ebb45-ea19-48d9-86e3-7d29ac93e571",
   "metadata": {},
   "source": [
    "# LLM response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a0f27102-2fb6-4af0-9cf0-58324d77ec1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: I want to open a restaurant for Italian food. Suggest a fancy name for this.\n",
      "LLM Response: \"Bella Cucina Ristorante\"\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Define the prompt template\n",
    "prompt_template_name = PromptTemplate(\n",
    "    input_variables=['cuisine'],\n",
    "    template=\"I want to open a restaurant for {cuisine} food. Suggest a fancy name for this.\"\n",
    ")\n",
    "\n",
    "# Format the prompt\n",
    "p = prompt_template_name.format(cuisine=\"Italian\")\n",
    "print(\"Prompt:\", p)\n",
    "\n",
    "# Initialize the LLM\n",
    "llm = ChatOpenAI(temperature=0.9)\n",
    "\n",
    "# Invoke the LLM and print the response\n",
    "response = llm.invoke(p)\n",
    "print(\"LLM Response:\", response.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b25de3be-2fef-4022-acb3-bbf64c08b616",
   "metadata": {},
   "source": [
    "# Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7b81e447-a27e-4538-b4bd-0167c18e988e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cuisine': 'Mexican', 'text': '\"El Sabor Mexicano\"'}\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import LLMChain\n",
    "\n",
    "llm = ChatOpenAI(temperature=0.9)\n",
    "chain = LLMChain(llm=llm, prompt=prompt_template_name)\n",
    "print(chain.invoke(\"Mexican\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2e51ba88-5ca6-41d9-9021-377da824e479",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mI want to open a restaurant for Mexican food. Suggest a fancy name for this.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\"El Sabroso Cocina\"\n"
     ]
    }
   ],
   "source": [
    "chain = LLMChain(llm=llm, prompt=prompt_template_name, verbose=True)\n",
    "response = chain.invoke({\"cuisine\": \"Mexican\"})\n",
    "print(response['text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "693d903f-f6b1-48c9-bcc9-a471f60ba6eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0.6)\n",
    "\n",
    "prompt_template_name = PromptTemplate(\n",
    "    input_variables=['cuisine'],\n",
    "    template=\"I want to open a restaurant for {cuisine} food. Suggest a fancy name for this.\"\n",
    ")\n",
    "\n",
    "name_chain = LLMChain(llm=llm, prompt=prompt_template_name)\n",
    "\n",
    "prompt_template_items = PromptTemplate(\n",
    "    input_variables=['restaurant_name'],\n",
    "    template=\"Suggest some menu items for {restaurant_name}\"\n",
    ")\n",
    "\n",
    "food_items_chain = LLMChain(llm=llm, prompt=prompt_template_items)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb44584e-6b85-4567-94b2-cd16c9e10447",
   "metadata": {},
   "source": [
    "# Simple Sequential Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2ea859d3-75a0-409e-95dc-9d934ff2510c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SimpleSequentialChain chain...\u001b[0m\n",
      "\u001b[36;1m\u001b[1;3m\"Spice Palace\"\u001b[0m\n",
      "\u001b[33;1m\u001b[1;3m1. Chicken Tikka Masala\n",
      "2. Lamb Vindaloo\n",
      "3. Vegetable Biryani\n",
      "4. Paneer Butter Masala\n",
      "5. Tandoori Chicken\n",
      "6. Saag Paneer\n",
      "7. Aloo Gobi\n",
      "8. Butter Chicken\n",
      "9. Dal Makhani\n",
      "10. Garlic Naan\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'input': 'Indian', 'output': '1. Chicken Tikka Masala\\n2. Lamb Vindaloo\\n3. Vegetable Biryani\\n4. Paneer Butter Masala\\n5. Tandoori Chicken\\n6. Saag Paneer\\n7. Aloo Gobi\\n8. Butter Chicken\\n9. Dal Makhani\\n10. Garlic Naan'}\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import SimpleSequentialChain\n",
    "\n",
    "chain = SimpleSequentialChain(chains=[name_chain, food_items_chain], verbose=True)\n",
    "\n",
    "content = chain.invoke(\"Indian\")\n",
    "print(content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b1eba9d-0a83-4fe9-8f18-c0475ece5dce",
   "metadata": {},
   "source": [
    "# Sequential Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b8569bb3-829a-42d5-a8ff-c30520aad7ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0.7)\n",
    "\n",
    "prompt_template_name = PromptTemplate(\n",
    "    input_variables=['cuisine'],\n",
    "    template=\"I want to open a restaurant for {cuisine} food. Suggest a fancy name for this.\"\n",
    ")\n",
    "\n",
    "name_chain = LLMChain(llm=llm, prompt=prompt_template_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "09d3d725-05a1-4537-9025-03e6ac7dbf58",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(temperature=0.7)\n",
    "\n",
    "prompt_template_items = PromptTemplate(\n",
    "    input_variables=['restaurant_name'],\n",
    "    template=\"Suggest some menu items for {restaurant_name}.\"\n",
    ")\n",
    "\n",
    "food_items_chain = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=prompt_template_items,\n",
    "    output_key=\"menu_items\"  # Optional, but required if used in a multi-step chain\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6d2abded-76bd-4edd-85ad-f55fe4708551",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SimpleSequentialChain chain...\u001b[0m\n",
      "\u001b[36;1m\u001b[1;3m\"Spice Palace\"\u001b[0m\n",
      "\u001b[33;1m\u001b[1;3m1. Chicken Tikka Masala\n",
      "2. Lamb Vindaloo\n",
      "3. Vegetable Biryani\n",
      "4. Paneer Tikka\n",
      "5. Butter Chicken\n",
      "6. Aloo Gobi\n",
      "7. Tandoori Chicken\n",
      "8. Chana Masala\n",
      "9. Naan bread\n",
      "10. Mango Lassi\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Indian',\n",
       " 'output': '1. Chicken Tikka Masala\\n2. Lamb Vindaloo\\n3. Vegetable Biryani\\n4. Paneer Tikka\\n5. Butter Chicken\\n6. Aloo Gobi\\n7. Tandoori Chicken\\n8. Chana Masala\\n9. Naan bread\\n10. Mango Lassi'}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"Indian\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d0bf70-b80b-4f91-9253-1739c6b8e164",
   "metadata": {},
   "source": [
    "# Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "eff7d6cf-509b-4ae1-a66c-379ec680c1ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure yoy have installed this package: pip install google-search-results\n",
    "from secret_key import serpapi_key\n",
    "# os.environ['SERPAPI_API_KEY'] = serpapi_key\n",
    "\n",
    "os.environ['SERPAPI_API_KEY'] = serpapi_key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ba04d2-2e20-4af0-8b45-197d8907200c",
   "metadata": {},
   "source": [
    "# serpapi and llm-math tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2bface9e-d60f-4874-ac66-5a7d4dce949c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I should use the Calculator tool to solve this math problem.\n",
      "Action: Calculator\n",
      "Action Input: 2022 + 5\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mAnswer: 2027\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m Now I need to search for the GDP of the US in 2027.\n",
      "Action: Search\n",
      "Action Input: \"GDP of US in 2027\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m['In the long-term, the United States GDP is projected to trend around 28756.00 USD Billion in 2026 and 29302.00 USD Billion in 2027, according to our econometric ...', \"Such growth is 1.9 percent in 2025 and 1.8 percent in 2026 and 2027 in CBO's projections.\", 'Release Table for 2027, Release Tables: Summary of Economic Projections. FRED: Download, graph, and track economic data.', 'Real gross domestic product (GDP) decreased at an annual rate of 0.3 percent in the first quarter of 2025 (January, February, and March), ...', \"As of 2025, it has the world's seventh highest nominal GDP per capita and ninth highest GDP per capita by PPP. The U.S. accounted for 26% of the global economy ...\", 'GDP, current prices. Billions of U.S. dollars. 30.51. thousand. Created with ... Millions of US Dollars. 357.19. thousand. Created with Highcharts 6.1.4. 2014.', 'CBO expects real (inflation-adjusted) GDP to grow by 2.3 percent this year and by 1.9 percent next year. ... and Economic Outlook: 2017 to 2027 (January 2017),.', 'GDP Growth of US economy to slow down gradually to 1.6% by 2027 from 2.8% now: S&P Global - The Tribune.']\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m After looking through the search results, I can see that the projected GDP of the US in 2027 is 29302.00 USD Billion.\n",
      "Final Answer: The GDP of the US in 2022 plus 5 is 29302.00 USD Billion.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'What was the GDP of US in 2022 plus 5?',\n",
       " 'output': 'The GDP of the US in 2022 plus 5 is 29302.00 USD Billion.'}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import OpenAI\n",
    "from langchain.agents import AgentType, initialize_agent, load_tools\n",
    "\n",
    "llm = OpenAI(temperature=0)\n",
    "\n",
    "tools = load_tools([\"serpapi\",\"llm-math\"],llm=llm)\n",
    "\n",
    "agent = initialize_agent(\n",
    "    tools = tools,\n",
    "    llm = llm,\n",
    "    agent = AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    verbose = True\n",
    ")\n",
    "\n",
    "agent.invoke(\"What was the GDP of US in 2022 plus 5?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "14f01687-42f9-43c2-91e0-e8f65ec2c876",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I should use Wikipedia to find information about Elon Musk's birthdate and age.\n",
      "Action: wikipedia\n",
      "Action Input: Elon Musk\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mPage: Elon Musk\n",
      "Summary: Elon Reeve Musk ( EE-lon; born June 28, 1971) is a businessman known for his leadership of Tesla, SpaceX, and X (formerly Twitter). Since 2025, he has been a senior advisor to United States president Donald Trump and the de facto head of the Department of Government Efficiency (DOGE). Musk has been considered the wealthiest person in the world since 2021; as of March 2025, Forbes estimates his net worth to be US$345 billion. He was named Time magazine's Person of the Year in 2021.\n",
      "Born to a wealthy family in Pretoria, South Africa, Musk emigrated in 1989 to Canada. He graduated from the University of Pennsylvania in the U.S. before moving to California to pursue business ventures. In 1995, Musk co-founded the software company Zip2. Following its sale in 1999, he co-founded X.com, an online payment company that later merged to form PayPal, which was acquired by eBay in 2002. That year, Musk also became a U.S. citizen.\n",
      "In 2002, Musk founded the space technology company SpaceX, becoming its CEO and chief engineer; the company has since led innovations in reusable rockets and commercial spaceflight. Musk joined the automaker Tesla as an early investor in 2004 and became its CEO and product architect in 2008; it has since become a leader in electric vehicles. In 2015, he co-founded OpenAI to advance artificial intelligence research but later left; growing discontent with the organization's direction in the 2020s led him to establish xAI. In 2022, he acquired the social network Twitter, implementing significant changes and rebranding it as X in 2023. In January 2025, he was appointed head of Trump's newly created DOGE. His other businesses include the neurotechnology company Neuralink, which he co-founded in 2016, and the tunneling company the Boring Company, which he founded in 2017.\n",
      "Musk's political activities and views have made him a polarizing figure. He has been criticized for making unscientific and misleading statements, including COVID-19 misinformation and promoting conspiracy theories, and affirming antisemitic, racist, and transphobic comments. His acquisition of Twitter was controversial due to a subsequent increase in hate speech and the spread of misinformation on the service. Especially since the 2024 U.S. presidential election, Musk has been heavily involved in politics as a vocal supporter of Trump. Musk was the largest donor in the 2024 U.S. presidential election and is a supporter of global far-right figures, causes, and political parties. His role in the second Trump administration, particularly in regards to DOGE, has attracted public backlash.\n",
      "\n",
      "\n",
      "\n",
      "Page: Elon Musk salute controversy\n",
      "Summary: On January 20, 2025, while speaking at a rally celebrating U.S. president Donald Trump's second inauguration, businessman and political figure Elon Musk twice made a gesture interpreted by many as a Nazi or a fascist Roman salute.\n",
      "It was widely condemned as an intentional Nazi salute in Germany, where making such gestures is illegal. The Anti-Defamation League said it was not a Nazi salute, but other Jewish organizations disagreed and condemned the salute. American public opinion was divided on partisan lines as to whether it was a fascist salute. Musk dismissed the accusations of Nazi sympathies, deriding them as \"dirty tricks\" and a \"tired\" attack. Neo-Nazi and white supremacist groups celebrated it as a Nazi salute. Multiple European political parties demanded that Musk be banned from entering their countries.\n",
      "\n",
      "\n",
      "\n",
      "Page: Views of Elon Musk\n",
      "Summary: Elon Musk is the owner of multiple companies, the wealthiest individual in the world, and a US government employee. Having rejected the conservative label, Musk has described himself as a political moderate; his views have become more right-wing over time, and have been characterized as libertarian and far-right. As the owner of Twitter, he has  suppressed critics, and after his involvement in European politics, his views have received criticism from some\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I should use the information from Wikipedia to calculate Elon Musk's age in 2025.\n",
      "Action: Calculator\n",
      "Action Input: 2025 - 1971\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mAnswer: 54\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I now know the final answer.\n",
      "Final Answer: Elon Musk will be 54 years old in 2025.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'When was Elon musk born? What is his age right now in 2025?',\n",
       " 'output': 'Elon Musk will be 54 years old in 2025.'}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm = OpenAI(temperature=0)\n",
    "\n",
    "tools = load_tools([\"wikipedia\",\"llm-math\"],llm=llm)\n",
    "\n",
    "agent = initialize_agent(\n",
    "    tools = tools,\n",
    "    llm = llm,\n",
    "    agent = AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    verbose = True\n",
    ")\n",
    "\n",
    "agent.invoke(\"When was Elon musk born? What is his age right now in 2025?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "978423db-8ab6-4cee-8921-71cbdcf8279a",
   "metadata": {},
   "source": [
    "## Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "64c8fb92-4113-4797-8ac1-f766d5c153f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\"El Sabor de México\" (The Flavor of Mexico)\n"
     ]
    }
   ],
   "source": [
    "chain = LLMChain(llm=llm,prompt=prompt_template_name)\n",
    "name = chain.invoke(\"Mexican\")\n",
    "print(name['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0cd93abf-e066-401a-9757-9fe379eada53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\"Spice Palace\"\n"
     ]
    }
   ],
   "source": [
    "name = chain.invoke(\"Indian\")\n",
    "print(name['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "41837bac-2822-4202-99ed-c2ffce810972",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain.memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "27d1888c-6192-4832-b631-dbcbcc9d53bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NoneType"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(chain.memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d945e910-2100-47a8-916e-0951242c2f52",
   "metadata": {},
   "source": [
    "### ConversationBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "aefb13bd-449f-4919-8c61-d7856f2e1f24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cuisine': 'Mexican', 'history': [HumanMessage(content='Mexican', additional_kwargs={}, response_metadata={}), AIMessage(content='\\n\\n\"El Sabor de México\" (The Flavor of Mexico)', additional_kwargs={}, response_metadata={})], 'text': '\\n\\n\"El Sabor de México\" (The Flavor of Mexico)'}\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import LLMChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "memory = ConversationBufferMemory(return_messages=True)\n",
    "chain = LLMChain(llm=llm,prompt=prompt_template_name,memory=memory)\n",
    "name  = chain.invoke({\"cuisine\":\"Mexican\"})\n",
    "print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0e7decf9-2cd9-47fe-8e72-85f0ad8e6622",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cuisine': 'Arabic', 'history': [HumanMessage(content='Mexican', additional_kwargs={}, response_metadata={}), AIMessage(content='\\n\\n\"El Sabor de México\" (The Flavor of Mexico)', additional_kwargs={}, response_metadata={}), HumanMessage(content='Arabic', additional_kwargs={}, response_metadata={}), AIMessage(content='\\n\\n\"Al-Jannah Bistro\"', additional_kwargs={}, response_metadata={})], 'text': '\\n\\n\"Al-Jannah Bistro\"'}\n"
     ]
    }
   ],
   "source": [
    "name = chain.invoke({\"cuisine\": \"Arabic\"})\n",
    "print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "0d98d51e-57eb-4637-bb9f-0f5b98567171",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HumanMessage(content='Mexican', additional_kwargs={}, response_metadata={}), AIMessage(content='\\n\\n\"El Sabor de México\" (The Flavor of Mexico)', additional_kwargs={}, response_metadata={}), HumanMessage(content='Arabic', additional_kwargs={}, response_metadata={}), AIMessage(content='\\n\\n\"Al-Jannah Bistro\"', additional_kwargs={}, response_metadata={})]\n"
     ]
    }
   ],
   "source": [
    "print(chain.memory.buffer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "597fe2db-8375-467a-b23f-56f0ebeda13e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HumanMessage(content='Mexican', additional_kwargs={}, response_metadata={}), AIMessage(content='\\n\\n\"El Sabor de México\" (The Flavor of Mexico)', additional_kwargs={}, response_metadata={}), HumanMessage(content='Arabic', additional_kwargs={}, response_metadata={}), AIMessage(content='\\n\\n\"Al-Jannah Bistro\"', additional_kwargs={}, response_metadata={})]\n"
     ]
    }
   ],
   "source": [
    "print(chain.memory.chat_memory.messages)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b89c8ac0-c1cc-4132-9e8f-62677cdf8042",
   "metadata": {},
   "source": [
    "## Conversation Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "9680816d-b44c-4c9b-80c6-f75a2c3a86bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! I'm here and ready to assist you. How can I help you today?\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.chat_history import InMemoryChatMessageHistory\n",
    "\n",
    "# Define your LLM\n",
    "llm = ChatOpenAI(temperature=0.7)\n",
    "\n",
    "# Define the prompt\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful assistant.\"),\n",
    "    (\"human\", \"{input}\"),\n",
    "])\n",
    "\n",
    "# Create a RunnableWithMessageHistory\n",
    "runnable = RunnableWithMessageHistory(\n",
    "    runnable=prompt | llm,\n",
    "    get_session_history=lambda session_id: InMemoryChatMessageHistory()\n",
    ")\n",
    "\n",
    "# Simulate a session\n",
    "session_id = \"example-session\"\n",
    "response = runnable.invoke({\"input\": \"Hello, how are you?\"}, config={\"configurable\": {\"session_id\": session_id}})\n",
    "\n",
    "print(response.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "123d1730-0c28-4011-89fd-0e71aa661682",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The first cricket world cup was held in 1975 and was won by the West Indies team. They beat Australia in the final, with Clive Lloyd scoring a century and leading his team to victory. It was a historic moment for cricket and for the West Indies, as it was their first world cup win.\n",
      " 5+5 is 10.\n",
      " The captain of the winning team was Clive Lloyd. He was a legendary cricketer and a key player in the West Indies team during that time. He also led the team to their second world cup win in 1979.\n"
     ]
    }
   ],
   "source": [
    "print(convo.run(\"Who won the first cricket world cup?\"))\n",
    "print(convo.run(\"How much is 5+5?\"))\n",
    "print(convo.run(\"Who was the captain of the winning team?\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "8fc0313d-52fd-48ef-a6a2-5e331ae8bf2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: Who won the first cricket world cup?\n",
      "AI:  The first cricket world cup was held in 1975 and was won by the West Indies team. They beat Australia in the final, with Clive Lloyd scoring a century and leading his team to victory. It was a historic moment for cricket and for the West Indies, as it was their first world cup win.\n",
      "Human: How much is 5+5?\n",
      "AI:  5+5 is 10.\n",
      "Human: Who was the captain of the winning team?\n",
      "AI:  The captain of the winning team was Clive Lloyd. He was a legendary cricketer and a key player in the West Indies team during that time. He also led the team to their second world cup win in 1979.\n"
     ]
    }
   ],
   "source": [
    "print(convo.memory.buffer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ccfedf17-f54a-47c0-bc4b-73d70e6e6344",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first Cricket World Cup was won by the West Indies in 1975.\n"
     ]
    }
   ],
   "source": [
    "#Define the prompt template\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful assistant.\"),\n",
    "    (\"human\", \"{input}\")\n",
    "])\n",
    "\n",
    "# Initialize LLM\n",
    "llm = ChatOpenAI(temperature=0.7)\n",
    "\n",
    "# Create the runnable with history support\n",
    "runnable = RunnableWithMessageHistory(\n",
    "    runnable=prompt | llm,\n",
    "    get_session_history=lambda session_id: InMemoryChatMessageHistory()\n",
    ")\n",
    "\n",
    "# Use a consistent session_id for memory\n",
    "session_id = \"cricket-session\"\n",
    "\n",
    "# Run the chain\n",
    "response = runnable.invoke(\n",
    "    {\"input\": \"Who won the first cricket world cup?\"},\n",
    "    config={\"configurable\": {\"session_id\": session_id}}\n",
    ")\n",
    "\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "4e013c74-8cb5-41cf-ae16-ce7df36593b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConversationBufferWindowMemory(chat_memory=InMemoryChatMessageHistory(messages=[]), k=3)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory = ConversationBufferWindowMemory(k=3)  # remembers last 3 exchanges\n",
    "memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef66b83-ec99-46c0-9454-212bd8381c11",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
